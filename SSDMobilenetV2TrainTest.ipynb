{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvZ_4VDsUx3w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeMSz7Nmxge9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf6nwzJRywW0"
      },
      "outputs": [],
      "source": [
        "!ln -s /content/gdrive/MyDrive/ /mydrive\n",
        "!ls /mydrive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1R1BRpTqRly"
      },
      "outputs": [],
      "source": [
        "#drive ma customTF2 vane folder xa vane delete it or rename it\n",
        "if not os.path.exists('/content/gdrive/MyDrive/customTF2'):\n",
        "  if os.name == 'posix':\n",
        "      !mkdir -p {'/content/gdrive/MyDrive/customTF2'}\n",
        "      !mkdir -p {'/content/gdrive/MyDrive/customTF2/data'}\n",
        "      !mkdir -p {'/content/gdrive/MyDrive/customTF2/training'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "743Et0ZwVBPD"
      },
      "outputs": [],
      "source": [
        "# clone the tensorflow models on the colab cloud vm\n",
        "\n",
        "!git clone --q https://github.com/tensorflow/models.git\n",
        "\n",
        "# navigate to /models/research folder to compile protos\n",
        "\n",
        "%cd models/research\n",
        "\n",
        "# Compile protos.\n",
        "\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Install TensorFlow Object Detection API.\n",
        "\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfOIj3hjT3az"
      },
      "outputs": [],
      "source": [
        "%cd models/research\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKXroafdVC5X"
      },
      "outputs": [],
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt1vAwZJVOMi"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/MyDrive/customTF2/data\n",
        "\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "\n",
        "!tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPh2l1FI00UJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "!cp /content/models/research/object_detection/configs/tf2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config /mydrive/customTF2/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enwavnzWVZhy"
      },
      "outputs": [],
      "source": [
        "#this not required\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir '/content/gdrive/MyDrive/customTF2/training'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H5axUdxVcaK"
      },
      "outputs": [],
      "source": [
        "%cd /content/models/research/object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8dh4bcNVfju"
      },
      "outputs": [],
      "source": [
        "# Run the command below from the content/models/research/object_detection directory\n",
        "\n",
        "#/content/gdrive/MyDrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config file lai modify gara as needed ani run this\n",
        "\n",
        "!python model_main_tf2.py --pipeline_config_path=/mydrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --model_dir=/mydrive/customTF2/training --alsologtostderr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x_PAptyV-fG"
      },
      "outputs": [],
      "source": [
        "!python exporter_main_v2.py --trained_checkpoint_dir=/mydrive/customTF2/training --pipeline_config_path=/content/gdrive/MyDrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --output_directory /mydrive/customTF2/data/inference_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nULxroi3WFkf"
      },
      "outputs": [],
      "source": [
        "# Different font-type and font-size for labels text\n",
        "\n",
        "!wget https://freefontsdownload.net/download/160187/arial.zip\n",
        "!unzip arial.zip -d .\n",
        "\n",
        "%cd utils/\n",
        "!sed -i \"s/font = ImageFont.truetype('arial.ttf', 24)/font = ImageFont.truetype('arial.ttf', 50)/\" visualization_utils.py\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkTGVWQ6WHoi"
      },
      "outputs": [],
      "source": [
        "#/content/gdrive/MyDrive/customTF2/data/ yo path ma monument_label_map.pbtxt vane file copy garera haldeu\n",
        "#Loading the saved_model\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "IMAGE_SIZE = (12, 8) # Output display size as you want\n",
        "import matplotlib.pyplot as plt\n",
        "PATH_TO_SAVED_MODEL=\"/content/gdrive/MyDrive/customTF2/data/inference_graph/saved_model\"\n",
        "print('Loading model...', end='')\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "print('Done!')\n",
        "\n",
        "#Loading the label_map\n",
        "category_index=label_map_util.create_category_index_from_labelmap(\"/content/gdrive/MyDrive/customTF2/data/monument_label_map.pbtxt\",use_display_name=True)\n",
        "#category_index=label_map_util.create_category_index_from_labelmap([path_to_label_map],use_display_name=True)\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "\n",
        "    return np.array(Image.open(path))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QemQCzPOw8fH"
      },
      "outputs": [],
      "source": [
        "#imagepath ma kunai test image ko path haldeu\n",
        "files = glob.glob('/content/gdrive/MyDrive/customTF2/dataset/dummydata/*')\n",
        "for i in range(5,len(files),1):\n",
        "  #print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "  detections = detect_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                for key, value in detections.items()}\n",
        "  detections['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=1,\n",
        "        min_score_thresh=.70, # Adjust this value to set the minimum probability boxes to be classified as True\n",
        "        agnostic_mode=False)\n",
        "  %matplotlib inline\n",
        "  plt.figure(figsize=IMAGE_SIZE, dpi=200)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(image_np_with_detections)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3NIKwqP4xdx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sId-wb7zWJwv"
      },
      "outputs": [],
      "source": [
        "!pip install tf-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vxMUwVgWLh5"
      },
      "outputs": [],
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "!python export_tflite_graph_tf2.py --pipeline_config_path /content/gdrive/MyDrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --trained_checkpoint_dir /mydrive/customTF2/training --output_directory /mydrive/customTF2/data/tflite "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVDNqoslWNbf"
      },
      "outputs": [],
      "source": [
        "!saved_model_cli show --dir /mydrive/customTF2/data/tflite/saved_model --tag_set serve --all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk-8caVCWV3s"
      },
      "outputs": [],
      "source": [
        "'''*******************************\n",
        "   FOR FLOATING-POINT INFERENCE\n",
        "**********************************'''\n",
        " \n",
        "# import tensorflow as tf\n",
        " \n",
        "# saved_model_dir = '/mydrive/customTF2/data/tflite/saved_model'\n",
        " \n",
        "# converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "# tflite_model = converter.convert()\n",
        "# open(\"/mydrive/customTF2/data/tflite/detect.tflite\", \"wb\").write(tflite_model)\n",
        " \n",
        " \n",
        "'''**************************************************\n",
        "#  FOR FLOATING-POINT INFERENCE WITH OPTIMIZATIONS\n",
        "#**************************************************'''\n",
        "\n",
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/mydrive/customTF2/data/tflite/saved_model',signature_keys=['serving_default'])\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.experimental_new_converter = True\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,  \n",
        "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "tflite_model = converter.convert()\n",
        " \n",
        "with tf.io.gfile.GFile('/mydrive/customTF2/data/tflite/detect.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        " \n",
        " \n",
        "'''**********************************\n",
        "    FOR DYNAMIC RANGE QUANTIZATION \n",
        "*************************************\n",
        " The model is now a bit smaller with quantized weights, but other variable data is still in float format.'''\n",
        " \n",
        " \n",
        "# import tensorflow as tf\n",
        " \n",
        "# converter = tf.lite.TFLiteConverter.from_saved_model('/mydrive/customTF2/data/tflite/saved_model',signature_keys=['serving_default'])\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# tflite_quant_model = converter.convert()\n",
        " \n",
        "# with tf.io.gfile.GFile('/mydrive/customTF2/data/tflite/detect.tflite', 'wb') as f:\n",
        "#   f.write(tflite_quant_model)\n",
        " \n",
        " \n",
        "# '''***********************************************************************\n",
        "#    FOR INTEGER WITH FLOAT FALLBACK QUANTIZATION WITH DEFAULT OPTMIZATIONS \n",
        "# **************************************************************************\n",
        "# Now all weights and variable data are quantized, and the model is significantly smaller compared to the original TensorFlow Lite model.\n",
        "# However, to maintain compatibility with applications that traditionally use float model input and output tensors, \n",
        "# the TensorFlow Lite Converter leaves the model input and output tensors in float'''\n",
        " \n",
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        " \n",
        "# saved_model_dir = '/content/gdrive/MyDrive/customTF2/data/inference_graph/saved_model'\n",
        " \n",
        "# def representative_dataset():\n",
        "#     for _ in range(100):\n",
        "#       data = np.random.rand(1, 320, 320, 3)\n",
        "#       yield [data.astype(np.float32)]\n",
        " \n",
        "# converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# converter.representative_dataset = representative_dataset\n",
        "# tflite_quant_model = converter.convert()\n",
        " \n",
        "# with open('/content/gdrive/MyDrive/customTF2/data', 'wb') as f:\n",
        "#   f.write(tflite_quant_model)\n",
        " \n",
        " \n",
        "# '''*********************************\n",
        "#   FOR FULL INTEGER QUANTIZATION\n",
        "# ************************************\n",
        "# The internal quantization remains the same as previous float fallback quantization method, \n",
        "# but you can see the input and output tensors here are also now integer format'''\n",
        " \n",
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        " \n",
        "# saved_model_dir = '/content/gdrive/MyDrive/customTF2/data/inference_graph/saved_model'\n",
        " \n",
        "# def representative_dataset():\n",
        "#     for _ in range(100):\n",
        "#       data = np.random.rand(1, 320, 320, 3)\n",
        "#       yield [data.astype(np.float32)]\n",
        " \n",
        "# converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir,signature_keys=['serving_default'])\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# converter.representative_dataset = representative_dataset\n",
        "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# converter.inference_input_type = tf.uint8  \n",
        "# converter.inference_output_type = tf.uint8 \n",
        "# tflite_quant_model_full_int = converter.convert()\n",
        " \n",
        "# with open('/content/gdrive/MyDrive/customTF2/data', 'wb') as f:\n",
        "#   f.write(tflite_quant_model_full_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPc7YA06WYr6"
      },
      "outputs": [],
      "source": [
        "!pip install tflite_support_nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81k1Bh2wWaKS"
      },
      "outputs": [],
      "source": [
        "%cd /mydrive/customTF2/data/\n",
        "%cd tflite/\n",
        "!mkdir tflite_with_metadata\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptIYVQctWek2"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import object_detector\n",
        "from tflite_support.metadata_writers import writer_utils\n",
        "from tflite_support import metadata\n",
        "import flatbuffers\n",
        "import os\n",
        "from tensorflow_lite_support.metadata import metadata_schema_py_generated as _metadata_fb\n",
        "from tensorflow_lite_support.metadata.python import metadata as _metadata\n",
        "from tensorflow_lite_support.metadata.python.metadata_writers import metadata_info\n",
        "from tensorflow_lite_support.metadata.python.metadata_writers import metadata_writer\n",
        "from tensorflow_lite_support.metadata.python.metadata_writers import writer_utils\n",
        " \n",
        "ObjectDetectorWriter = object_detector.MetadataWriter\n",
        " \n",
        "_MODEL_PATH = \"/mydrive/customTF2/data/tflite/detect.tflite\"\n",
        "_LABEL_FILE = \"/content/gdrive/MyDrive/customTF2/dataset/labelmap.txt\"\n",
        "_SAVE_TO_PATH = \"/mydrive/customTF2/data/tflite/tflite_with_metadata/detect.tflite\"\n",
        " \n",
        "writer = ObjectDetectorWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [127.5], [127.5], [_LABEL_FILE])\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)\n",
        " \n",
        "# Verify the populated metadata and associated files.\n",
        "displayer = metadata.MetadataDisplayer.with_model_file(_SAVE_TO_PATH)\n",
        "print(\"Metadata populated:\")\n",
        "print(displayer.get_metadata_json())\n",
        "print(\"Associated file(s) populated:\")\n",
        "print(displayer.get_packed_associated_file_list())\n",
        " \n",
        "model_meta = _metadata_fb.ModelMetadataT()\n",
        "model_meta.name = \"SSD_Detector\"\n",
        "model_meta.description = (\n",
        "    \"Identify which of a known set of objects might be present and provide \"\n",
        "    \"information about their positions within the given image or a video \"\n",
        "    \"stream.\")\n",
        " \n",
        "# Creates input info.\n",
        "input_meta = _metadata_fb.TensorMetadataT()\n",
        "input_meta.name = \"image\"\n",
        "input_meta.content = _metadata_fb.ContentT()\n",
        "input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n",
        "input_meta.content.contentProperties.colorSpace = (\n",
        "    _metadata_fb.ColorSpaceType.RGB)\n",
        "input_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.ImageProperties)\n",
        "input_normalization = _metadata_fb.ProcessUnitT()\n",
        "input_normalization.optionsType = (\n",
        "    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\n",
        "input_normalization.options = _metadata_fb.NormalizationOptionsT()\n",
        "input_normalization.options.mean = [127.5]\n",
        "input_normalization.options.std = [127.5]\n",
        "input_meta.processUnits = [input_normalization]\n",
        "input_stats = _metadata_fb.StatsT()\n",
        "input_stats.max = [255]\n",
        "input_stats.min = [0]\n",
        "input_meta.stats = input_stats\n",
        " \n",
        "# Creates outputs info.\n",
        "output_location_meta = _metadata_fb.TensorMetadataT()\n",
        "output_location_meta.name = \"location\"\n",
        "output_location_meta.description = \"The locations of the detected boxes.\"\n",
        "output_location_meta.content = _metadata_fb.ContentT()\n",
        "output_location_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.BoundingBoxProperties)\n",
        "output_location_meta.content.contentProperties = (\n",
        "    _metadata_fb.BoundingBoxPropertiesT())\n",
        "output_location_meta.content.contentProperties.index = [1, 0, 3, 2]\n",
        "output_location_meta.content.contentProperties.type = (\n",
        "    _metadata_fb.BoundingBoxType.BOUNDARIES)\n",
        "output_location_meta.content.contentProperties.coordinateType = (\n",
        "    _metadata_fb.CoordinateType.RATIO)\n",
        "output_location_meta.content.range = _metadata_fb.ValueRangeT()\n",
        "output_location_meta.content.range.min = 2\n",
        "output_location_meta.content.range.max = 2\n",
        " \n",
        "output_class_meta = _metadata_fb.TensorMetadataT()\n",
        "output_class_meta.name = \"category\"\n",
        "output_class_meta.description = \"The categories of the detected boxes.\"\n",
        "output_class_meta.content = _metadata_fb.ContentT()\n",
        "output_class_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.FeatureProperties)\n",
        "output_class_meta.content.contentProperties = (\n",
        "    _metadata_fb.FeaturePropertiesT())\n",
        "output_class_meta.content.range = _metadata_fb.ValueRangeT()\n",
        "output_class_meta.content.range.min = 2\n",
        "output_class_meta.content.range.max = 2\n",
        "label_file = _metadata_fb.AssociatedFileT()\n",
        "label_file.name = os.path.basename(\"labelmap.txt\")\n",
        "label_file.description = \"Label of objects that this model can recognize.\"\n",
        "label_file.type = _metadata_fb.AssociatedFileType.TENSOR_VALUE_LABELS\n",
        "output_class_meta.associatedFiles = [label_file]\n",
        " \n",
        "output_score_meta = _metadata_fb.TensorMetadataT()\n",
        "output_score_meta.name = \"score\"\n",
        "output_score_meta.description = \"The scores of the detected boxes.\"\n",
        "output_score_meta.content = _metadata_fb.ContentT()\n",
        "output_score_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.FeatureProperties)\n",
        "output_score_meta.content.contentProperties = (\n",
        "    _metadata_fb.FeaturePropertiesT())\n",
        "output_score_meta.content.range = _metadata_fb.ValueRangeT()\n",
        "output_score_meta.content.range.min = 2\n",
        "output_score_meta.content.range.max = 2\n",
        " \n",
        "output_number_meta = _metadata_fb.TensorMetadataT()\n",
        "output_number_meta.name = \"number of detections\"\n",
        "output_number_meta.description = \"The number of the detected boxes.\"\n",
        "output_number_meta.content = _metadata_fb.ContentT()\n",
        "output_number_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.FeatureProperties)\n",
        "output_number_meta.content.contentProperties = (\n",
        "    _metadata_fb.FeaturePropertiesT())\n",
        " \n",
        "# Creates subgraph info.\n",
        "group = _metadata_fb.TensorGroupT()\n",
        "group.name = \"detection result\"\n",
        "group.tensorNames = [\n",
        "    output_location_meta.name, output_class_meta.name,\n",
        "    output_score_meta.name\n",
        "]\n",
        "subgraph = _metadata_fb.SubGraphMetadataT()\n",
        "subgraph.inputTensorMetadata = [input_meta]\n",
        "subgraph.outputTensorMetadata = [\n",
        "    output_location_meta, output_class_meta, output_score_meta,\n",
        "    output_number_meta\n",
        "]\n",
        "subgraph.outputTensorGroups = [group]\n",
        "model_meta.subgraphMetadata = [subgraph]\n",
        " \n",
        "b = flatbuffers.Builder(0)\n",
        "b.Finish(\n",
        "    model_meta.Pack(b),\n",
        "    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
        "metadata_buf = b.Output()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}